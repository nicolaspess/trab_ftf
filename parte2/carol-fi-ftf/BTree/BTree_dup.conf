[DEFAULT]

debug = False

# Name of the gdb executable, usualy is "gdb-mic" for Xeon Phi
gdbExecName = gdb

# How many interrupt signals to send sequentially
seqSignals = 10
# How many random threads will attempt to send interrupt signals
numThreadsFI = 4

# Max time to send signal. It should be the app exec time in seconds
maxWaitTime = 30

# Commands to set the session inside GDB environment
# gdbInitStrings = file /tmp/quicksort/quicksort;set args 50000 4 /tmp/quicksort/inputsort_134217728 /tmp/quicksort/output_50000
gdbInitStrings = file /tmp/BTree-dup/main; set args /tmp/BTree-dup/input_100000 /tmp/BTree-dup/output_100000 /tmp/BTree-dup-detection.log /tmp/BTree-dup/output2_100000

goldFile = /tmp/BTree-dup/gold_100000
outputFile = /tmp/BTree-dup/output_100000

# Shell command to send SIGINT to the application being tested
signalCmd = killall -2 main

# Kill commands to exit all applications (GDB and the application tested)
# Need to ensure safe termination before another fault injection test
killStrs = killall -9 gdb;killall -9 main


# Start and end time to try randomly inject a fault
initSignal = 0
endSignal = 2
# Which fault model to use, 0 -> single; 1 -> double; 2 -> random; 3 -> zeros; 4 -> least significant bits (LSB)

[BTree-dup-random]
faultModel = 2

[BTree-dup-single]
faultModel = 0

[BTree-dup-double]
faultModel = 1

[BTree-dup-zeros]
faultModel = 3

[BTree-dup-lsb]
faultModel = 4